---
title: "Linear Regression With Pytorch Neural Network and Numpy in Colab Python"
date: 2022-07-29T16:14:47-07:00
---

Here is YouTube video of this article: {{< youtube OKBQeIiP3I8 >}}  

[Google Colab Notebook of Linear Regression Using Pytorch and Numpy in Python](https://colab.research.google.com/drive/1dMXc0lgGXlXBmNiJmGmsPuEZinZbsr1U?usp=sharing) . 


![Colab Picture 1 of ANN Regression](/img/ann-01.jpg)
![Colab Picture 2 of ANN Regression](/img/ann-02.jpg)
![Colab Picture 3 of ANN Regression](/img/ann-03.jpg)
![Colab Picture 4 of ANN Regression](/img/ann-04.jpg)
![Colab Picture 5 of ANN Regression](/img/ann-05.jpg)
![Colab Picture 6 of ANN Regression](/img/ann-06.jpg)
![Colab Picture 7 of ANN Regression](/img/ann-07.jpg)

hi everyone in this video i'm going to be talking about linear regression using the pi torch and numpy libraries in python now linear regression and statistic we use it to predict a continuous value and a continued value for example you can see right here is the distance of a galaxy how far uh it is away from us and the velocity is the uh the one that we try to predict uh how fast it is moving away from us right here this right here basically show us that the universe is expanding okay and the regret linear regression formula is similar to the line slope intercept form that many of us are familiar in math which is y equal to m x plus b you can see right here right here is the regression formula um except for the error term right here right it's very similar okay so in order to do linear regression we first need to import the numpy and the python library we also going to import the matlab lib to for data visualization okay so here are the data there's about 23 data data pair x and y distance how far how far a galaxy is away from us and how fast it is moving and you can see right here right the farthest away the faster that it is moving okay so the first thing we're going to do is that we're going to put this data into the variable distance and the variable velocity right here okay we're also going to

find the max the standard max velocity magnitude of x velocity right here the reason is because we're going to need to kind of re-normalize this number a little bit so that it would work well in the neural network model pi torch okay and then for visualization i'm i'm doing a scatter plot of distance versus velocity right here and with the title helper small right here and you can see that there's generally a linear relationship between x and y or distance and velocity at this point right here i am dividing the data by its max values just to normalize kind of normalize the um the data a bit so that it will work well work better and the pi touch library okay and then i'm going to we have to convert it to a tensor type right here and then we also have to reshape it into an one column vector and in this situation is 23 okay and you can see right here right here is the shape less than t and this is t stands for tensor and then velocity t tensor shape right here 23 and one so when we have the data ready we can create our model which is just a symbol a linear model using the new rule network in pi torch and then the in features basically we only have one variable coming in and then we only have another variable coming out distant velocity right here right and you can see that here is our the model linear and the bias by d4 is true okay next we're going to do next thing we're going to do is we're going to set the learning rate and we're going to choose the um a loss function by the learning rate i choose this about 0.05 and the loss function i'm using the mean square error okay of the pi torch library and then for the optimize i'm just using the stochastic gradient descent and passing the parameter of my model and the learning rate okay this for loop right here is where the learning is the model is actually doing the learning right here so for each iteration we gonna predict the value using our model right here and then after each prediction we kind of calculate the uh the loss using our mean square error loss function right here so here's the actual data here's the data here's the last function and for each iteration i'm storing this large function right here so that we can visualize how it changed over each iteration okay and this step right here is where we um do backward propagation to relearn to let the model relearn and get it get a new prediction so we set the gradient back to zero we do we do backward propagation right here and then this one right here is just for book skipping right here okay and here this step right here is where we visualize the losses you can see right here right it learned uh pretty quickly and you know it's dropped down to uh just this values right here and then just you know the learning uh decreased um the learning is really fast over here and it's decreased over here so maybe you know maybe a 300 iteration for this for this learning rate would be good enough okay so here is the number of okay and then the for this one right here i calculate the um uh i'm calculating i'm taking each losses okay and then i plot that i plot it right here and then the final predicted value is the red dot right here okay now we can look at the individual parameter from the appliance you know the final applause by just using the item function method right here all right so the final app loss is about 0.02 and then we can also bring out we can also calculate the correlation of coefficient by passing the

actual data and predicted data right here okay from this we can find the f statistic by going into the particular element of the array and the situation zero and one right here okay

so here is the plotted data versus actual data right here yeah right here okay and then we can get the slope from this the about uh predicted the model to calculate the age of the universe right here so from our model we can get out the parameter w and b and the w is basically this love right but we have to re-normalize it back to our original scale so that it would work and in this situation right here the slop calculation is uh 74 and the age of the universe is basically the inverse of this one right here and then convert it into year and this formula right here is just invert that so it's going to give the age of the universe a second and we have to convert that into year right so according to our neural network model our age of the universe is about 13.1 billion years okay you know for a simple model like this right here we could also use uh numpy which actually is a bit more straightforward and efficient and you can see right here right we had the two values again we passed the uh the x and y into the polarized fifth function method of numpy and then one is just for linear uh two is for example to the second power and then if you see right here right here is a slope the hyperfit uh parameter it's gonna return the slope and the intercept point right here here is another visualization of this um polyfit line the red line right here with the data okay and then using the inverse of the slope uh hub of it zero right here we can also find the age of the universe as before and we calculate that it is about 12.1 billion years with the numpy method okay so here is an example of linear regression using you know actual data from herbal data in numpy and pi torch i hope that you find this video helpful if you do please give a like again give a thumb up subscribe and have a good day