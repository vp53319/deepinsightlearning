---
title: "Logarithm in Python and Colab"
date: 2022-07-07T16:58:21-07:00
---

hi everyone in this video i'm going to be discussing about the logarithmic function and logarithm log quickly function is important in machine learning because the machine learning in a way is an optimization process and you know and we use a lot of logarithmic function in optimization the reason is because sometimes when you have value that are closely spaced right there the computer is going to have a challenging time try to compute find the maximum or minimum in that situation right there if you put it through a logarithmic function with a small value you'll spread out the log a bit more and stretch it out so it's easier to compute and if you take a look and in this collab notebook right here the first thing we do is we import numpy and math.lib pi plot as plt this one is to do the plotting uh and in python and colab then the next thing is that we want to pay attention to is log or the natural log is base e right and e is 2.17 the x exponential or the natural exponent only and log is only d5 for x is greater than greater than zero and log yeah as you can see from down here the log increase monotonically to infinity but it does slowly and then as it gets closer and closer to zero the value of it spread out um more right there for small x right here okay and um and you can have different kind of base you can have base 2 base e's or base 10 base is natural law and we use a lot a lot of that in machine learning because the natural the natural law of base e is inverse to the exponentials or exponent right here and then as i mentioned earlier log is not monotonic meaning that if x increases or decreases uh the log is also increase it and decrease it there's no like for example the side function there's no up and down and up and down it just increase or decrease monotonically as x increase or decrease and then minimize so in that situation right there minimizing x is similar to minimizing loss of x right there and in instances where the spread is where the value is small minimizing log of x right there might be a bit less challenging for a computer to execute and minimizing x right here for example so the way that i the i plot the the log function is that i create um a list of 100 data points uh equally spaced between 0.01 and 5 right there so this line space does that minimum value maximum value and you know it'll create a list of in this situation 100 points even in space and then the next thing i do is i call numpy to do the natural log of x and store that in the variable log x you know base each right here um log x e right here and then the next thing i'm doing i do is that i plot the value this is a y axis this is the x right here and then the marketplace color is y you see this the this area inside the circle right here right if you change it for example blue it's going gonna be blue so in this situation i do y and then the shape of the point i have it as a circle uh circle and this line right now that's right here mean that i just connect the uh the connector point right here okay and then here's the x label as there's a white blade ball and we'll show it right here so here's a lock function you can see it increase um not monotonically and slowly to infinitive as x got larger and as i get smaller right here you see that the spread the stretch get bigger and bigger get bigger the next example you can see right here also is that you can also have log of base 2 or base 10 in numpy as log 2 and log 10 like this respectively and you can see right here i plot these two logs of using the same data over on here i block i plot at base 2 and base 10. so essentially the log base 2 base 10 tends on natural log base e exponential it's similar characteristic the only thing different is that this the slope of the upper log right here and by the way uh the legend right here you can plot you know for matlab slip you can plot two plot on the same canvas the same figure and you can also specify the legend right here base 2 and base 10 right and so this way right here you know which the which plot that belongs to which which base by hand in our example finally uh you know to show but not to prove that uh the natural log is the inverse of um of the the log and vice versa you can see right here i have exponential and if i take the log natural log of the exponential we get a straight line like one one two two three three four four five five right here and another thing is that if you do the reverse right if you have the if you have you take the exponential of the natural log here we take the log of exponential here we take the exponential of the of the log you see that it'll give us the same um a straight line uh like this right here and by the way you know in in this block right here right i'm using the latex notation instead of just a regular notation sometimes this could give us a better uh presentation of the formula in this situation it doesn't doesn't make that much of a difference but in other cases right there it can present it better so here's an example of the log function that would you know which has uh roles and important in machine learning and or deep learning implemented in collab using the numpy library i hope this helped you um if you like it please if you like it please you know give a thumb up leave a comment give a like and subscribe thank you and have a good day

{{< youtube I5e-LKxNLo8 >}} 


[Google Colab Notebook of Logarithm](https://colab.research.google.com/drive/1d9r0--yUFBdM-7nDY30i9HRAVvV3I2Ut?usp=sharing) . 


![Colab Picture 1 of Logarithm](/img/log-01.jpg)
![Colab Picture 2 of Logarithm](/img/log-02.jpg)
![Colab Picture 3 of Logarithm](/img/log-03.jpg)



